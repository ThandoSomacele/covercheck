# ğŸ‡¿ğŸ‡¦ CoverCheck - Medical Aid Assistant

**Your South African medical aid questions answered with accurate, up-to-date information.**

A modern AI-powered medical aid assistant that helps South Africans understand and compare medical aid plans from the top 3 providers. Built with quality data, semantic search, and RAG (Retrieval-Augmented Generation).

## ğŸ¯ Project Status

**âœ… Phase 1 Complete:** High-quality data scraping from top 3 SA medical aid providers

- **23 verified documents** from Discovery Health, Bonitas Medical Fund, and Momentum Health
- **88% quality rate** with comprehensive plan and benefits information
- **Zero 404 errors** - all URLs verified and working
- Ready for Phase 2: Database Setup

**ğŸ”„ Phase 2 Next:** PostgreSQL + pgvector database setup for semantic search

## âœ¨ Features

### Current (Phase 1)
- ğŸ¥ **Top 3 SA Providers** - Discovery Health, Bonitas Medical Fund, Momentum Health
- ğŸ“Š **Comprehensive Coverage** - All major plans, benefits, and claims information
- âœ… **Quality Validated** - Medical terminology verified, content accuracy confirmed
- ğŸ” **Smart Scraping** - Resilient scraper with rate limiting and error recovery

### Coming Soon (Phase 2+)
- ğŸ—„ï¸ **Vector Database** - PostgreSQL + pgvector for semantic search
- ğŸ¤– **RAG System** - Accurate answers backed by real documentation
- ğŸŒ **Web Interface** - Modern SvelteKit chat UI
- ğŸ‡¿ğŸ‡¦ **SA Context** - Rands (R), SA English, and medical aid terminology

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- npm or yarn
- PostgreSQL with pgvector extension (for Phase 2+)
- Ollama (for local embeddings)

### Installation

```bash
# Clone the repository
git clone https://github.com/ThandoSomacele/covercheck.git
cd covercheck

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env
# Edit .env and add your API keys and database connection string
```

### Environment Variables

Create a `.env` file in the project root with the following variables:

```env
# Database Configuration
DB_CONNECTION_STRING=postgresql://user:password@host:port/database

# OpenRouter API Configuration
OPENROUTER_API_KEY=sk-or-v1-your_api_key_here
```

**âš ï¸ SECURITY WARNING:**
- **NEVER commit your `.env` file to git**
- **NEVER hardcode API keys or secrets in source code**
- The `.env` file is already in `.gitignore` for your protection
- Use `.env.example` as a template (it contains no real secrets)

### Running the Scrapers

```bash
# Scrape all 3 providers
npm run scrape

# Scrape individual providers
npm run scrape:discovery
npm run scrape:bonitas
npm run scrape:momentum

# Analyze data quality
npx tsx scripts/validate-content.ts
npx tsx scripts/analyze-scraped-data.ts
```

## ğŸ“ Project Structure

```
covercheck/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ insurance/              # Static insurance data
â”‚   â”‚   â”‚   â”œâ”€â”€ documents-sa.ts     # SA medical aid documents
â”‚   â”‚   â”‚   â””â”€â”€ insurance-*-glossary.ts
â”‚   â”‚   â””â”€â”€ server/
â”‚   â”‚       â”œâ”€â”€ rag.ts              # RAG logic (future)
â”‚   â”‚       â””â”€â”€ scrapers/           # Web scraping system
â”‚   â”‚           â”œâ”€â”€ BaseScraper.ts
â”‚   â”‚           â”œâ”€â”€ DiscoveryHealthScraper.ts
â”‚   â”‚           â”œâ”€â”€ BonitasScraper.ts
â”‚   â”‚           â”œâ”€â”€ MomentumHealthScraper.ts
â”‚   â”‚           â””â”€â”€ ScraperOrchestrator.ts
â”‚   â””â”€â”€ routes/
â”‚       â”œâ”€â”€ +page.svelte            # Chat UI (future)
â”‚       â””â”€â”€ api/chat/+server.ts     # API endpoint (future)
â”œâ”€â”€ scripts/                         # Utility scripts
â”‚   â”œâ”€â”€ scrape.ts                   # Main scraping CLI
â”‚   â”œâ”€â”€ validate-content.ts         # Quality validation
â”‚   â””â”€â”€ analyze-scraped-data.ts     # Data analysis
â”œâ”€â”€ docs/                            # Complete documentation
â”‚   â”œâ”€â”€ README.md                   # Documentation index
â”‚   â”œâ”€â”€ SCRAPING.md                 # Scraping system guide
â”‚   â”œâ”€â”€ VERIFIED_URLS.md            # Verified provider URLs
â”‚   â””â”€â”€ SCRAPER_FIX_PLAN.md         # Quality improvement process
â”œâ”€â”€ scraped-data/                    # JSON output (gitignored)
â”œâ”€â”€ legacy/                          # Old implementations
â””â”€â”€ COVERCHECK_ROADMAP.md           # Development roadmap
```

## ğŸ“Š Data Quality

### Current Scrape Results

| Provider | Documents | Quality Rate | Avg. Content |
|----------|-----------|--------------|--------------|
| Discovery Health | 13/14 | 93% | 10,000 chars |
| Momentum Health | 9/10 | 90% | 10,500 chars |
| Bonitas Medical Fund | 1/2 | 50% | 193,754 chars |
| **Total** | **23/26** | **88%** | **~10,000 chars** |

### Content Coverage

âœ… **Plan Information**
- All major plans from each provider
- Plan benefits and exclusions
- Coverage details

âœ… **Benefits Documentation**
- Hospital benefits
- Day-to-day benefits
- Chronic illness benefits

âœ… **Support Information**
- Claims processes
- Comparison tools
- Contact information

## ğŸ› ï¸ Development Roadmap

### âœ… Phase 1: Data Scraping (Complete)
- [x] Research and verify provider URLs
- [x] Build scraping system with Playwright
- [x] Implement quality validation
- [x] Scrape top 3 SA providers
- [x] Achieve 20+ quality documents

### ğŸ”„ Phase 2: Database Setup (Next)
- [ ] Set up PostgreSQL + pgvector
- [ ] Design database schema
- [ ] Process and chunk documents
- [ ] Generate embeddings
- [ ] Implement semantic search

### ğŸ“… Phase 3: RAG Implementation
- [ ] Build RAG pipeline
- [ ] Integrate with Ollama/OpenRouter
- [ ] Implement query processing
- [ ] Add source citations

### ğŸ“… Phase 4: Web Interface
- [ ] SvelteKit frontend
- [ ] Chat UI with message history
- [ ] API endpoints
- [ ] User authentication
- [ ] Deploy to production

See [`COVERCHECK_ROADMAP.md`](COVERCHECK_ROADMAP.md) for detailed roadmap.

## ğŸ“š Documentation

All documentation is in the [`docs/`](docs/) directory:

- **[docs/README.md](docs/README.md)** - Documentation index
- **[docs/SCRAPING.md](docs/SCRAPING.md)** - Complete scraping guide
- **[docs/VERIFIED_URLS.md](docs/VERIFIED_URLS.md)** - Working provider URLs
- **[docs/SCRAPER_FIX_PLAN.md](docs/SCRAPER_FIX_PLAN.md)** - Quality improvement process
- **[docs/PROJECT_OVERVIEW.md](docs/PROJECT_OVERVIEW.md)** - Project goals and architecture
- **[docs/SETUP_SA.md](docs/SETUP_SA.md)** - SA-specific setup guide

## ğŸ§ª Technology Stack

**Current:**
- **SvelteKit** - Full-stack framework
- **TypeScript** - Type safety
- **Playwright** - Web scraping
- **Cheerio** - HTML parsing

**Planned:**
- **PostgreSQL + pgvector** - Vector database
- **Ollama** - Local AI model runner
- **OpenRouter** - Cloud AI API (alternative)
- **Svelte 5** - Reactive UI

## ğŸ”§ Adding New Providers

Want to add another medical aid provider? See the [Adding New Scrapers](docs/SCRAPING.md#adding-new-scrapers) guide.

Quick overview:
1. Create a new scraper class extending `BaseScraper`
2. Define target URLs and selectors
3. Register in `ScraperOrchestrator`
4. Test and validate quality

## ğŸ¤ Contributing

This is a learning project documenting the journey of building a production RAG system. Contributions, suggestions, and feedback are welcome!

## ğŸ“ License

See LICENSE file for details.

## ğŸ™ Acknowledgments

Built with:
- [SvelteKit](https://kit.svelte.dev/)
- [Playwright](https://playwright.dev/)
- [Cheerio](https://cheerio.js.org/)

Data sourced from:
- [Discovery Health](https://www.discovery.co.za/medical-aid)
- [Bonitas Medical Fund](https://www.bonitas.co.za)
- [Momentum Health](https://www.momentum.co.za)

---

**Made with â¤ï¸ for South Africans who deserve simple, accurate medical aid information.**

**Current Version:** Phase 1 Complete
**Last Updated:** 2025-11-07
