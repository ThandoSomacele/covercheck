# Database Configuration
# PostgreSQL connection string with pgvector extension enabled
# Format: postgresql://username:password@host:port/database
DB_CONNECTION_STRING=postgresql://user:password@localhost:5432/covercheck

# OpenRouter API Configuration
# Get your API key from https://openrouter.ai/keys
# Used for cloud LLM queries (Gemini, Llama, Mistral)
OPENROUTER_API_KEY=sk-or-v1-your_api_key_here

# Application Configuration (Optional)
# Set to 'production' for production deployment
NODE_ENV=development

# Embedding Provider Configuration
# Choose your embedding provider: ollama (local), huggingface (free cloud), openai (paid cloud)
# Default: ollama
EMBEDDING_PROVIDER=ollama

# Ollama Configuration (Local Development - FREE)
# Local Ollama server URL for embeddings
# Requires Ollama running locally with nomic-embed-text model
# Default: http://localhost:11434
# OLLAMA_HOST=http://localhost:11434

# Hugging Face Configuration (Cloud - FREE TIER AVAILABLE)
# Get your API key from https://huggingface.co/settings/tokens
# FREE tier includes generous rate limits - perfect for production!
# No credit card required to start
# EMBEDDING_PROVIDER=huggingface
# HUGGINGFACE_API_KEY=hf_your_api_key_here

# OpenAI Configuration (Cloud - PAID, when you have funds)
# Get your API key from https://platform.openai.com/api-keys
# Cost: ~$0.02 per 1M tokens (very affordable)
# EMBEDDING_PROVIDER=openai
# OPENAI_API_KEY=sk-your_api_key_here
